{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625c703f-e6fc-4894-9395-62345e3c78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import platform\n",
    "import subprocess\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b754810-5ff6-4fea-abd8-6dc1b524a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_separator():\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "def check_cuda():\n",
    "    \"\"\"Comprehensive CUDA and GPU diagnostics\"\"\"\n",
    "    print_separator()\n",
    "    print(\"üîç GPU DIAGNOSTICS REPORT üîç\")\n",
    "    print_separator()\n",
    "    \n",
    "    # System information\n",
    "    print(\"SYSTEM INFORMATION:\")\n",
    "    print(f\"  OS: {platform.system()} {platform.release()} ({platform.machine()})\")\n",
    "    print(f\"  Python: {platform.python_version()} ({sys.executable})\")\n",
    "    print(f\"  PyTorch: {torch.__version__}\")\n",
    "    print(f\"  PyTorch installed at: {os.path.dirname(torch.__file__)}\")\n",
    "    \n",
    "    # Check if CUDA is available according to PyTorch\n",
    "    print_separator()\n",
    "    print(\"PYTORCH CUDA STATUS:\")\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"  torch.cuda.is_available(): {cuda_available}\")\n",
    "    \n",
    "    if cuda_available:\n",
    "        print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"  cuDNN version: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else 'Not available'}\")\n",
    "        print(f\"  CUDA device count: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        # Display information for each GPU\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"\\n  DEVICE {i}:\")\n",
    "            print(f\"    Name: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"    Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "            \n",
    "            # Memory information\n",
    "            total_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)  # Convert to GB\n",
    "            print(f\"    Total memory: {total_memory:.2f} GB\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è CUDA is not available in PyTorch!\")\n",
    "        print(\"  This suggests either:\")\n",
    "        print(\"    - You have no NVIDIA GPU\")\n",
    "        print(\"    - Your PyTorch installation doesn't support CUDA\")\n",
    "        print(\"    - There's a CUDA version mismatch\")\n",
    "    \n",
    "    # Check for GPU via nvidia-smi\n",
    "    print_separator()\n",
    "    print(\"NVIDIA-SMI STATUS:\")\n",
    "    \n",
    "    try:\n",
    "        nvidia_smi = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        if nvidia_smi.returncode == 0:\n",
    "            print(\"  NVIDIA GPU detected by system:\")\n",
    "            print(\"\\n\" + nvidia_smi.stdout)\n",
    "            \n",
    "            if not cuda_available:\n",
    "                print(\"\\n  ‚ö†Ô∏è MISMATCH DETECTED: GPU found by system but not by PyTorch!\")\n",
    "                print(\"  Likely causes:\")\n",
    "                print(\"    1. PyTorch was installed without CUDA support\")\n",
    "                print(\"    2. CUDA version mismatch between PyTorch and drivers\")\n",
    "                print(\"    3. Environment issues (e.g., PATH settings)\")\n",
    "                \n",
    "                print(\"\\n  SOLUTION:\")\n",
    "                print(\"    Reinstall PyTorch with CUDA support:\")\n",
    "                if platform.system() == \"Windows\":\n",
    "                    print(\"      pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\")\n",
    "                else:\n",
    "                    print(\"      pip install torch torchvision\")\n",
    "        else:\n",
    "            print(\"  nvidia-smi command failed. No NVIDIA driver or GPU detected by system.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to run nvidia-smi: {str(e)}\")\n",
    "        print(\"  This suggests NVIDIA drivers are not installed or accessible.\")\n",
    "\n",
    "    # Check for MPS (Apple Silicon)\n",
    "    print_separator()\n",
    "    print(\"APPLE SILICON STATUS:\")\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        print(\"  MPS is available - Apple Silicon acceleration can be used\")\n",
    "    else:\n",
    "        if platform.system() == \"Darwin\" and platform.machine() == \"arm64\":\n",
    "            print(\"  ‚ö†Ô∏è Running on Apple Silicon but MPS is not available!\")\n",
    "            print(\"  Make sure you're using PyTorch 1.12+ with macOS 12.3+\")\n",
    "        else:\n",
    "            print(\"  Not running on Apple Silicon\")\n",
    "    \n",
    "    print_separator()\n",
    "    print(\"RECOMMENDATION:\")\n",
    "    if cuda_available:\n",
    "        print(\"  ‚úÖ CUDA is working! Use device='cuda' for GPU acceleration.\")\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        print(\"  ‚úÖ Use device='mps' for Apple Silicon acceleration.\")\n",
    "    else:\n",
    "        has_nvidia_gpu = False\n",
    "        try:\n",
    "            has_nvidia_gpu = subprocess.run(['nvidia-smi'], capture_output=True).returncode == 0\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        if has_nvidia_gpu:\n",
    "            print(\"  ‚ö†Ô∏è You have an NVIDIA GPU but PyTorch can't use it!\")\n",
    "            print(\"  Reinstall PyTorch with the correct CUDA version:\")\n",
    "            print(\"    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\")\n",
    "        else:\n",
    "            print(\"  ‚ÑπÔ∏è No GPU acceleration available. Using CPU only.\")\n",
    "    \n",
    "    print_separator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd863a01-f3df-4cbb-8e69-193e3fb8ed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "üîç GPU DIAGNOSTICS REPORT üîç\n",
      "\n",
      "================================================================================\n",
      "\n",
      "SYSTEM INFORMATION:\n",
      "  OS: Linux 6.5.0-45-generic (x86_64)\n",
      "  Python: 3.12.7 (/home/jose.lopes/anaconda3/envs/ia/bin/python)\n",
      "  PyTorch: 2.6.0+cu124\n",
      "  PyTorch installed at: /home/jose.lopes/anaconda3/envs/ia/lib/python3.12/site-packages/torch\n",
      "\n",
      "================================================================================\n",
      "\n",
      "PYTORCH CUDA STATUS:\n",
      "  torch.cuda.is_available(): True\n",
      "  CUDA version: 12.4\n",
      "  cuDNN version: 90100\n",
      "  CUDA device count: 1\n",
      "\n",
      "  DEVICE 0:\n",
      "    Name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "    Capability: (8, 9)\n",
      "    Total memory: 5.77 GB\n",
      "\n",
      "================================================================================\n",
      "\n",
      "NVIDIA-SMI STATUS:\n",
      "  NVIDIA GPU detected by system:\n",
      "\n",
      "Mon Jun 30 14:52:59 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...    Off | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   50C    P8               4W / 115W |     51MiB /  6141MiB |     36%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2705      G   /usr/lib/xorg/Xorg                           45MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "APPLE SILICON STATUS:\n",
      "  Not running on Apple Silicon\n",
      "\n",
      "================================================================================\n",
      "\n",
      "RECOMMENDATION:\n",
      "  ‚úÖ CUDA is working! Use device='cuda' for GPU acceleration.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
